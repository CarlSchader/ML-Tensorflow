{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "  freq1, freq2, offset1, offset2 = np.random.rand(4, batch_size, 1)\n",
    "  time = np.linspace(0, 1, n_steps)\n",
    "  series =  0.5 * np.sin((time - offset1) * (freq1 * 10 + 10))\n",
    "  series +=  0.2 * np.sin((time - offset2) * (freq2 * 10 + 10))\n",
    "  series +=  0.1 * np.random.rand(batch_size, n_steps) * 0.5\n",
    "  return series[..., np.newaxis].astype(np.float32)\n",
    "\n",
    "print(generate_time_series(32, 5).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_val, y_val = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive forecasting (last element in data as prediction)\n",
    "# difficult to outperform\n",
    "\n",
    "print(np.mean(keras.losses.mean_squared_error(y_val, X_val[:, -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFNN\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.Flatten(input_shape=[50, 1]),\n",
    "  keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[keras.metrics.MSE],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "print(tf.reduce_mean(keras.losses.MSE(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RNN\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[keras.metrics.MSE],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "print(tf.reduce_mean(keras.losses.MSE(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep RNN\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(20, input_shape=[None, 1], return_sequences=True),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=False),\n",
    "  keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[keras.metrics.MSE],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "print(tf.reduce_mean(keras.losses.MSE(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using same model to predict multiple steps\n",
    "new_steps = 10\n",
    "series = generate_time_series(1, n_steps + new_steps)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:n_steps + new_steps]\n",
    "X = X_new\n",
    "for step in range(new_steps):\n",
    "  y_pred_one = model.predict(X[:, step:])[:, np.newaxis, :]\n",
    "  X = np.concatenate((X, y_pred_one), axis=1)\n",
    "y_pred = X[:, n_steps:]\n",
    "print(y_pred)\n",
    "print(tf.reduce_mean(keras.losses.MSE(Y_new, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing 10 at a times\n",
    "n_steps = 50\n",
    "new_steps = 10\n",
    "series = generate_time_series(10000, n_steps + new_steps)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -new_steps:]\n",
    "X_val, y_val = series[7000:9000, :n_steps], series[7000:9000, -new_steps:]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -new_steps:]\n",
    "\n",
    "print(series.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(20, input_shape=[None, 1], return_sequences=True),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=False),\n",
    "  keras.layers.Dense(10),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[keras.metrics.MSE],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.reduce_mean(keras.losses.MSE(y_test.reshape(len(y_test), len(y_test[0])), model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence to sequence data\n",
    "example_count = 10000\n",
    "prediction_length = 10\n",
    "Y = np.empty((example_count, n_steps, prediction_length))\n",
    "for step_ahead in range(1, prediction_length + 1):\n",
    "  Y[:, :, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]\n",
    "y_train = Y[:7000]\n",
    "y_val = Y[7000:9000]\n",
    "y_test = Y[9000:]\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric for evaluating since only the final output matters.\n",
    "# During training it helped to use all outputs.\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "  return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "# sequence to sequence model\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "  keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[last_time_step_mse],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "print(tf.reduce_mean(last_time_step_mse(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOT SURE WHY THIS DOESN'T WORK\n",
    "\n",
    "# class LNSimpleRNNCell(keras.layers.Layer):\n",
    "#   def __init__(self, units, activation='tanh', **kwargs):\n",
    "#     super().__init__(**kwargs)\n",
    "#     self.state_size = units\n",
    "#     self.output_size = units\n",
    "    \n",
    "#     self.layer_norm = keras.layers.LayerNormalization()\n",
    "#     self.activation = keras.activations.get(activation)\n",
    "  \n",
    "#   def build(self, batch_input_shape):\n",
    "#     print(batch_input_shape)\n",
    "#     self.simpleRNNCell = keras.layers.SimpleRNN(self.output_size, activation=None, input_shape=batch_input_shape)\n",
    "#     super().build(batch_input_shape)\n",
    "  \n",
    "#   def call(self, inputs, states):\n",
    "#     new_outputs, new_states = self.simpleRNNCell(inputs, states)\n",
    "#     normalized_outputs = self.activation(self.layer_norm(new_outputs))\n",
    "#     return normalized_outputs, [normalized_outputs]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WON'T WORK BECAUSE OF ABOVE CELL\n",
    "# model = keras.models.Sequential([\n",
    "#   keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),\n",
    "#   keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "#   keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "# ])\n",
    "\n",
    "# model.compile(\n",
    "#   loss=keras.losses.MSE,\n",
    "#   metrics=[last_time_step_mse],\n",
    "#   optimizer=keras.optimizers.Adam()\n",
    "# )\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=20)\n",
    "# print(tf.reduce_mean(last_time_step_mse(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.LSTM(20, return_sequences=True),\n",
    "  keras.layers.LSTM(20, return_sequences=True),\n",
    "  keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[last_time_step_mse],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "print(tf.reduce_mean(last_time_step_mse(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "  keras.layers.GRU(20, return_sequences=True),\n",
    "  keras.layers.GRU(20, return_sequences=True),\n",
    "  keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[last_time_step_mse],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train[:, 3::2], epochs=20)\n",
    "print(tf.reduce_mean(last_time_step_mse(y_test[:, 3::2], model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
    "for dilation in [1, 2, 4, 8] * 2:\n",
    "  model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding='causal', activation='relu', dilation_rate=dilation))\n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[last_time_step_mse],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "print(tf.reduce_mean(last_time_step_mse(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape, model.predict(X_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset = tfds.load('imagenet_sketch', as_supervised=True)\n",
    "dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(40000)\n",
    "val = dataset.skip(40000).take(5000)\n",
    "test = dataset.skip(45000)\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def dsprint(ds, num=1):\n",
    "  # print(len(ds))\n",
    "  for item in ds.take(num):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {}\n",
    "# create sketch rnn dataset\n",
    "data_dir = os.path.join('../', 'data', 'quickdraw')\n",
    "filenames = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "class_count = len(filenames)\n",
    "\n",
    "for i in range(class_count):\n",
    "  class_map[filenames[i]] = i\n",
    "\n",
    "def load_data(filenames, batch_size=32, set_type='train'):\n",
    "  np_list = [np.load(filename, encoding='latin1', allow_pickle=True)[set_type] for filename in filenames]\n",
    "  ds_list = [tf.data.Dataset.from_generator(lambda: np_list[i], tf.int16).map(lambda X: (X, i)) for i in range(len(np_list))]\n",
    "  ds = tf.data.Dataset.from_tensor_slices(ds_list).interleave(\n",
    "    lambda ds: ds,\n",
    "    cycle_length=len(ds_list),\n",
    "    block_length=1,\n",
    "  )\n",
    "  ds = ds.shuffle(len(ds_list) * 10).map(lambda X, label: (tf.reverse(X, [1]), label)).padded_batch(batch_size, padded_shapes=([None, 3], ()))\n",
    "  return ds.map(lambda X, label: (tf.reverse(X, [1]), label))\n",
    "\n",
    "test_set = np.load('../data/quickdraw/ambulance.full.npz', encoding='latin1', allow_pickle=True)['train']\n",
    "print(len(test_set))\n",
    "for item in test_set:\n",
    "  print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(filenames, set_type='train')\n",
    "val = load_data(filenames, set_type='valid')\n",
    "test = load_data(filenames, set_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traint = train.take(800).prefetch(1)\n",
    "valt = val.take(100).prefetch(1)\n",
    "testt = test.take(100).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_sketch(sketch, label=None):\n",
    "    origin = np.array([[0., 0., 0.]])\n",
    "    sketch = np.r_[origin, sketch]\n",
    "    stroke_end_indices = np.argwhere(sketch[:, -1]==1.)[:, 0]\n",
    "    coordinates = np.cumsum(sketch[:, :2], axis=0)\n",
    "    strokes = np.split(coordinates, stroke_end_indices + 1)\n",
    "    plt.plot(coordinates[:, 0], -coordinates[:, 1], \"y:\")\n",
    "    for stroke in strokes:\n",
    "        plt.plot(stroke[:, 0], -stroke[:, 1], \".-\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "i = 10\n",
    "for item in traint.take(1):\n",
    "    sketch = item[0][i]\n",
    "    file = filenames[item[1][i].numpy()]\n",
    "    print(file)\n",
    "    draw_sketch(sketch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHY WONT THIS WORK\n",
    "# Exercise number 9\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#   keras.layers.InputLayer(input_shape=[None, 3]),\n",
    "#   # keras.layers.BatchNormalization(),\n",
    "#   keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "#   # keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "#   # keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   # keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   keras.layers.LSTM(100, return_sequences=True),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   keras.layers.LSTM(100, return_sequences=True),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   keras.layers.LSTM(100, return_sequences=False),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   keras.layers.BatchNormalization(),\n",
    "#   keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'),\n",
    "#   keras.layers.BatchNormalization(),\n",
    "#   # keras.layers.Dropout(0.5),\n",
    "#   keras.layers.Dense(50, activation='relu', kernel_initializer='he_normal'),\n",
    "#   keras.layers.BatchNormalization(),\n",
    "#   # keras.layers.Dropout(0.5),\n",
    "#   keras.layers.Dense(20, activation='relu', kernel_initializer='he_normal'),\n",
    "#   keras.layers.BatchNormalization(),\n",
    "#   # keras.layers.Dropout(0.5),\n",
    "#   keras.layers.Dense(class_count, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#   keras.layers.InputLayer(input_shape=[None, 3]),\n",
    "#   keras.layers.Conv1D(filters=50, kernel_size=4, strides=2, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=50, kernel_size=4, strides=1, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=100, kernel_size=4, strides=2, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=100, kernel_size=4, strides=1, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=200, kernel_size=4, strides=2, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=200, kernel_size=4, strides=1, padding='same'),\n",
    "#   keras.layers.GlobalAveragePooling1D(),\n",
    "#   keras.layers.Flatten(),\n",
    "#   keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'),\n",
    "#   # keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'),\n",
    "#   keras.layers.Dense(class_count, activation='softmax')\n",
    "# ])\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 3]))\n",
    "for dilation in [1, 2, 4, 8, 16] * 2:\n",
    "  model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding='causal', activation='relu', dilation_rate=dilation))\n",
    "# model.add(keras.layers.Conv1D(filters=class_count, kernel_size=1, activation='softmax'))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add((keras.layers.Dense(class_count, activation='softmax')))\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.sparse_categorical_crossentropy,\n",
    "  metrics=[keras.metrics.sparse_categorical_accuracy],\n",
    "  optimizer=keras.optimizers.Nadam()\n",
    "  # optimizer=keras.optimizers.SGD(0.001, 0.9, True)\n",
    ")\n",
    "\n",
    "# print(tf.argmax(model.predict(batch), axis=1))\n",
    "\n",
    "model.fit(traint, validation_data=valt, epochs=20, callbacks=[\n",
    "  keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "  keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 10\n",
    "from IPython.display import Audio\n",
    "\n",
    "def notes_to_frequencies(notes):\n",
    "  # Frequency doubles when you go up one octave; there are 12 semi-tones\n",
    "  # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.\n",
    "  return 2 ** ((np.array(notes) - 69) / 12) * 440\n",
    "\n",
    "def frequencies_to_samples(frequencies, tempo, sample_rate):\n",
    "  note_duration = 60 / tempo # the tempo is measured in beats per minutes\n",
    "  # To reduce click sound at every beat, we round the frequencies to try to\n",
    "  # get the samples close to zero at the end of each note.\n",
    "  frequencies = np.round(note_duration * frequencies) / note_duration\n",
    "  n_samples = int(note_duration * sample_rate)\n",
    "  time = np.linspace(0, note_duration, n_samples)\n",
    "  sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)\n",
    "  # Removing all notes with frequencies ≤ 9 Hz (includes note 0 = silence)\n",
    "  sine_waves *= (frequencies > 9.).reshape(-1, 1)\n",
    "  return sine_waves.reshape(-1)\n",
    "\n",
    "def chords_to_samples(chords, tempo, sample_rate):\n",
    "  freqs = notes_to_frequencies(chords)\n",
    "  freqs = np.r_[freqs, freqs[-1:]] # make last note a bit longer\n",
    "  merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)\n",
    "                    for melody in freqs.T], axis=0)\n",
    "  n_fade_out_samples = sample_rate * 60 // tempo # fade out last note\n",
    "  fade_out = np.linspace(1., 0., n_fade_out_samples)**2\n",
    "  merged[-n_fade_out_samples:] *= fade_out\n",
    "  return merged\n",
    "\n",
    "def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):\n",
    "  samples = amplitude * chords_to_samples(chords, tempo, sample_rate)\n",
    "  if filepath:\n",
    "    from scipy.io import wavfile\n",
    "    samples = (2**15 * samples).astype(np.int16)\n",
    "    wavfile.write(filepath, sample_rate, samples)\n",
    "    return display(Audio(filepath))\n",
    "  else:\n",
    "    return display(Audio(samples, rate=sample_rate))\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "def load_set(dir, batch_size=32):\n",
    "  X = [os.path.join(dir, filename) for filename in os.listdir(dir)]\n",
    "  X = [read_csv(path).values for path in X]\n",
    "  # X = np.split(X, batch_size)\n",
    "  max_len = max(*[len(song) for song in X])\n",
    "  print(max_len)\n",
    "  X = [np.pad(song, ((640 - len(song), 0), (0, 0))) for song in X]\n",
    "  Y = [np.append(song[1:], [[0, 0, 0, 0]], axis=0) for song in X]\n",
    "  return np.stack(X, axis=0).astype(np.float32), np.stack(Y, axis=0).astype(np.float32) / 87\n",
    "\n",
    "X_train, Y_train = load_set('../data/jsb_chorales/train/')\n",
    "X_val, Y_val = load_set('../data/jsb_chorales/valid/')\n",
    "X_test, Y_test = load_set('../data/jsb_chorales/test/')\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(8)\n",
    "val = tf.data.Dataset.from_tensor_slices((X_val, Y_val)).batch(8)\n",
    "test = tf.data.Dataset.from_tensor_slices((X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_chords(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "  return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "# model = keras.models.Sequential()\n",
    "# model.add(keras.layers.InputLayer(input_shape=[None, 4]))\n",
    "# for dilation in [1, 2, 4, 8, 16, 32] * 4:\n",
    "#   model.add(keras.layers.Conv1D(filters=100, kernel_size=2, padding='causal', activation='relu', dilation_rate=dilation))\n",
    "# model.add(keras.layers.Conv1D(filters=4, kernel_size=1))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=[None, 4]),\n",
    "  keras.layers.LSTM(100, return_sequences=True),\n",
    "  keras.layers.LSTM(100, return_sequences=True),\n",
    "  keras.layers.LSTM(100, return_sequences=False),\n",
    "  # keras.layers.TimeDistributed(keras.layers.Dense(4)),\n",
    "  keras.layers.Dense(4),\n",
    "])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(model.predict(X_train).shape)\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  # loss=last_time_step_mse,\n",
    "  # metrics=[keras.metrics.MSE],\n",
    "  metrics=[last_time_step_mse],\n",
    "  # optimizer=keras.optimizers.Nadam()\n",
    "  optimizer=keras.optimizers.SGD(0.035, 0.9, True)\n",
    ")\n",
    "\n",
    "# print(tf.argmax(model.predict(batch), axis=1))\n",
    "\n",
    "model.fit(train, validation_data=val, epochs=160, callbacks=[\n",
    "  keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True),\n",
    "  keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_test[0].shape)\n",
    "# print(Y_test[0].reshape(1, *Y_test[0].shape).shape)\n",
    "print(Y_test[0].reshape(1, *Y_test[0].shape))\n",
    "print(model.predict(Y_test[0].reshape(1, *Y_test[0].shape)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Aug 30 2022, 04:58:14) [Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9120ca18d9a6352a9f63d878cd22df8740658f703b5d617e89c0216f7e3927ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
