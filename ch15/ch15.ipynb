{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "  freq1, freq2, offset1, offset2 = np.random.rand(4, batch_size, 1)\n",
    "  time = np.linspace(0, 1, n_steps)\n",
    "  series =  0.5 * np.sin((time - offset1) * (freq1 * 10 + 10))\n",
    "  series +=  0.2 * np.sin((time - offset2) * (freq2 * 10 + 10))\n",
    "  series +=  0.1 * np.random.rand(batch_size, n_steps) * 0.5\n",
    "  return series[..., np.newaxis].astype(np.float32)\n",
    "\n",
    "print(generate_time_series(32, 5).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_val, y_val = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive forecasting (last element in data as prediction)\n",
    "# difficult to outperform\n",
    "\n",
    "print(np.mean(keras.losses.mean_squared_error(y_val, X_val[:, -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFNN\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.Flatten(input_shape=[50, 1]),\n",
    "  keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[keras.metrics.MSE],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "print(tf.reduce_mean(keras.losses.MSE(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RNN\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[keras.metrics.MSE],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "print(tf.reduce_mean(keras.losses.MSE(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep RNN\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(20, input_shape=[None, 1], return_sequences=True),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=False),\n",
    "  keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[keras.metrics.MSE],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "print(tf.reduce_mean(keras.losses.MSE(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using same model to predict multiple steps\n",
    "new_steps = 10\n",
    "series = generate_time_series(1, n_steps + new_steps)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:n_steps + new_steps]\n",
    "X = X_new\n",
    "for step in range(new_steps):\n",
    "  y_pred_one = model.predict(X[:, step:])[:, np.newaxis, :]\n",
    "  X = np.concatenate((X, y_pred_one), axis=1)\n",
    "y_pred = X[:, n_steps:]\n",
    "print(y_pred)\n",
    "print(tf.reduce_mean(keras.losses.MSE(Y_new, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing 10 at a times\n",
    "n_steps = 50\n",
    "new_steps = 10\n",
    "series = generate_time_series(10000, n_steps + new_steps)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -new_steps:]\n",
    "X_val, y_val = series[7000:9000, :n_steps], series[7000:9000, -new_steps:]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -new_steps:]\n",
    "\n",
    "print(series.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(20, input_shape=[None, 1], return_sequences=True),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=False),\n",
    "  keras.layers.Dense(10),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[keras.metrics.MSE],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.reduce_mean(keras.losses.MSE(y_test.reshape(len(y_test), len(y_test[0])), model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence to sequence data\n",
    "example_count = 10000\n",
    "prediction_length = 10\n",
    "Y = np.empty((example_count, n_steps, prediction_length))\n",
    "for step_ahead in range(1, prediction_length + 1):\n",
    "  Y[:, :, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]\n",
    "y_train = Y[:7000]\n",
    "y_val = Y[7000:9000]\n",
    "y_test = Y[9000:]\n",
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric for evaluating since only the final output matters.\n",
    "# During training it helped to use all outputs.\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "  return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])\n",
    "\n",
    "# sequence to sequence model\n",
    "model = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "  keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[last_time_step_mse],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "print(tf.reduce_mean(last_time_step_mse(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOT SURE WHY THIS DOESN'T WORK\n",
    "\n",
    "# class LNSimpleRNNCell(keras.layers.Layer):\n",
    "#   def __init__(self, units, activation='tanh', **kwargs):\n",
    "#     super().__init__(**kwargs)\n",
    "#     self.state_size = units\n",
    "#     self.output_size = units\n",
    "    \n",
    "#     self.layer_norm = keras.layers.LayerNormalization()\n",
    "#     self.activation = keras.activations.get(activation)\n",
    "  \n",
    "#   def build(self, batch_input_shape):\n",
    "#     print(batch_input_shape)\n",
    "#     self.simpleRNNCell = keras.layers.SimpleRNN(self.output_size, activation=None, input_shape=batch_input_shape)\n",
    "#     super().build(batch_input_shape)\n",
    "  \n",
    "#   def call(self, inputs, states):\n",
    "#     new_outputs, new_states = self.simpleRNNCell(inputs, states)\n",
    "#     normalized_outputs = self.activation(self.layer_norm(new_outputs))\n",
    "#     return normalized_outputs, [normalized_outputs]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # WON'T WORK BECAUSE OF ABOVE CELL\n",
    "# model = keras.models.Sequential([\n",
    "#   keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True, input_shape=[None, 1]),\n",
    "#   keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "#   keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "# ])\n",
    "\n",
    "# model.compile(\n",
    "#   loss=keras.losses.MSE,\n",
    "#   metrics=[last_time_step_mse],\n",
    "#   optimizer=keras.optimizers.Adam()\n",
    "# )\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=20)\n",
    "# print(tf.reduce_mean(last_time_step_mse(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.LSTM(20, return_sequences=True),\n",
    "  keras.layers.LSTM(20, return_sequences=True),\n",
    "  keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[last_time_step_mse],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "print(tf.reduce_mean(last_time_step_mse(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "  keras.layers.GRU(20, return_sequences=True),\n",
    "  keras.layers.GRU(20, return_sequences=True),\n",
    "  keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[last_time_step_mse],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train[:, 3::2], epochs=20)\n",
    "print(tf.reduce_mean(last_time_step_mse(y_test[:, 3::2], model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
    "for dilation in [1, 2, 4, 8] * 2:\n",
    "  model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding='causal', activation='relu', dilation_rate=dilation))\n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.MSE,\n",
    "  metrics=[last_time_step_mse],\n",
    "  optimizer=keras.optimizers.Adam()\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "print(tf.reduce_mean(last_time_step_mse(y_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape, model.predict(X_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset = tfds.load('imagenet_sketch', as_supervised=True)\n",
    "dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(40000)\n",
    "val = dataset.skip(40000).take(5000)\n",
    "test = dataset.skip(45000)\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def dsprint(ds, num=1):\n",
    "  # print(len(ds))\n",
    "  for item in ds.take(num):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sketch rnn dataset\n",
    "data_dir = os.path.join('../', 'data', 'quickdraw')\n",
    "filenames = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)][:3]\n",
    "class_count = len(filenames)\n",
    "\n",
    "def load_data(filenames, batch_size=32, set_type='train'):\n",
    "  np_list = [np.load(filename, encoding='latin1', allow_pickle=True)['train'] for filename in filenames]\n",
    "  ds_list = [tf.data.Dataset.from_generator(lambda: np_list[i], tf.int16).map(lambda X: (X / 255, i)) for i in range(len(np_list))]\n",
    "  ds = tf.data.Dataset.from_tensor_slices(ds_list).interleave(\n",
    "    lambda ds: ds,\n",
    "    cycle_length=len(ds_list),\n",
    "    block_length=1,\n",
    "  )\n",
    "  ds = ds.shuffle(len(ds_list) * 10).map(lambda X, label: (tf.reverse(X, [1]), label)).padded_batch(batch_size, padded_shapes=([None, 3], ()))\n",
    "  return ds.map(lambda X, label: (tf.reverse(X, [1]), label))\n",
    "\n",
    "  # return ds.shuffle(len(ds_list) * 10).padded_batch(batch_size, padded_shapes=([None, 3], ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(filenames, set_type='train')\n",
    "val = load_data(filenames, set_type='valid')\n",
    "test = load_data(filenames, set_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "traint = train.take(800).prefetch(1)\n",
    "valt = val.take(100).prefetch(1)\n",
    "testt = test.take(100).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 10s 10ms/step - loss: 1.0987 - sparse_categorical_accuracy: 0.2998 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.3331 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 1.0987 - sparse_categorical_accuracy: 0.3007 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.3325 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 1.0987 - sparse_categorical_accuracy: 0.2995 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.3331 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 1.0986 - sparse_categorical_accuracy: 0.3084 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.3325 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 1.0986 - sparse_categorical_accuracy: 0.3077 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.3322 - lr: 5.0000e-04\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 1.0986 - sparse_categorical_accuracy: 0.3076 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.3322 - lr: 2.5000e-04\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 8s 11ms/step - loss: 1.0986 - sparse_categorical_accuracy: 0.3149 - val_loss: 1.0986 - val_sparse_categorical_accuracy: 0.3331 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "220/800 [=======>......................] - ETA: 5s - loss: 1.0986 - sparse_categorical_accuracy: 0.3335"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m   loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39msparse_categorical_crossentropy,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m   metrics\u001b[39m=\u001b[39m[keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39msparse_categorical_accuracy],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m   optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mNadam()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m   \u001b[39m# optimizer=keras.optimizers.SGD(0.001, 0.9, True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# print(tf.argmax(model.predict(batch), axis=1))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(traint, validation_data\u001b[39m=\u001b[39;49mvalt, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m   keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, restore_best_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m   keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mReduceLROnPlateau(factor\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,patience\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X34sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m ])\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# WHY WONT THIS WORK\n",
    "# Exercise number 9\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#   keras.layers.InputLayer(input_shape=[None, 3]),\n",
    "#   # keras.layers.BatchNormalization(),\n",
    "#   keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "#   # keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "#   # keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   # keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding='valid'),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   keras.layers.LSTM(100, return_sequences=True),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   keras.layers.LSTM(100, return_sequences=True),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   keras.layers.LSTM(100, return_sequences=False),\n",
    "#   # keras.layers.LayerNormalization(),\n",
    "#   keras.layers.BatchNormalization(),\n",
    "#   keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'),\n",
    "#   keras.layers.BatchNormalization(),\n",
    "#   # keras.layers.Dropout(0.5),\n",
    "#   keras.layers.Dense(50, activation='relu', kernel_initializer='he_normal'),\n",
    "#   keras.layers.BatchNormalization(),\n",
    "#   # keras.layers.Dropout(0.5),\n",
    "#   keras.layers.Dense(20, activation='relu', kernel_initializer='he_normal'),\n",
    "#   keras.layers.BatchNormalization(),\n",
    "#   # keras.layers.Dropout(0.5),\n",
    "#   keras.layers.Dense(class_count, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# model = keras.models.Sequential([\n",
    "#   keras.layers.InputLayer(input_shape=[None, 3]),\n",
    "#   keras.layers.Conv1D(filters=50, kernel_size=4, strides=2, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=50, kernel_size=4, strides=1, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=100, kernel_size=4, strides=2, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=100, kernel_size=4, strides=1, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=200, kernel_size=4, strides=2, padding='same'),\n",
    "#   keras.layers.Conv1D(filters=200, kernel_size=4, strides=1, padding='same'),\n",
    "#   keras.layers.GlobalAveragePooling1D(),\n",
    "#   keras.layers.Flatten(),\n",
    "#   keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'),\n",
    "#   # keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'),\n",
    "#   keras.layers.Dense(class_count, activation='softmax')\n",
    "# ])\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 3]))\n",
    "for dilation in [1, 2, 4, 8, 16] * 2:\n",
    "  model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding='causal', activation='relu', dilation_rate=dilation))\n",
    "# model.add(keras.layers.Conv1D(filters=class_count, kernel_size=1, activation='softmax'))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add((keras.layers.Dense(class_count, activation='softmax')))\n",
    "\n",
    "model.compile(\n",
    "  loss=keras.losses.sparse_categorical_crossentropy,\n",
    "  metrics=[keras.metrics.sparse_categorical_accuracy],\n",
    "  optimizer=keras.optimizers.Nadam()\n",
    "  # optimizer=keras.optimizers.SGD(0.001, 0.9, True)\n",
    ")\n",
    "\n",
    "# print(tf.argmax(model.predict(batch), axis=1))\n",
    "\n",
    "model.fit(traint, validation_data=valt, epochs=20, callbacks=[\n",
    "  keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "  keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Pack as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Pack] name: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(testt)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pred \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39margmax(pred, \u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch15/ch15.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m true \u001b[39m=\u001b[39m  tf\u001b[39m.\u001b[39;49mone_hot(\u001b[39mlist\u001b[39;49m(testt\u001b[39m.\u001b[39;49munbatch()), class_count, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Pack as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Pack] name: 0"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# pred = model.predict(testt)\n",
    "# pred = tf.argmax(pred, 1)\n",
    "# true =  tf.one_hot(list(), class_count, axis=1)\n",
    "# # print(confusion_matrix(testt, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9120ca18d9a6352a9f63d878cd22df8740658f703b5d617e89c0216f7e3927ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
