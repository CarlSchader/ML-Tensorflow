{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;rnd&#x27;, RandomForestClassifier()),\n",
       "                             (&#x27;log&#x27;, LogisticRegression()),\n",
       "                             (&#x27;svc&#x27;, SVC(probability=True))],\n",
       "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rnd&#x27;, RandomForestClassifier()),\n",
       "                             (&#x27;log&#x27;, LogisticRegression()),\n",
       "                             (&#x27;svc&#x27;, SVC(probability=True))],\n",
       "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rnd</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>log</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('rnd', RandomForestClassifier()),\n",
       "                             ('log', LogisticRegression()),\n",
       "                             ('svc', SVC(probability=True))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rnd_clf = RandomForestClassifier()\n",
    "log_clf = LogisticRegression()\n",
    "svc_clf = SVC(probability=True)\n",
    "voting_clf = VotingClassifier(\n",
    "  estimators=[('rnd', rnd_clf), ('log', log_clf), ('svc', svc_clf)],\n",
    "  voting='soft',\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.8315\n",
      "RandomForestClassifier 0.85\n",
      "SVC 0.867\n",
      "VotingClassifier 0.862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svc_clf, voting_clf):\n",
    "  clf.fit(X_train, y_train)\n",
    "  print(clf.__class__.__name__, accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864625\n",
      "[[882 114]\n",
      " [153 851]]\n",
      "0.8665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "  DecisionTreeClassifier(),\n",
    "  n_estimators=500,\n",
    "  max_samples=100, bootstrap=True, n_jobs=-1, # Use all cores\n",
    "  oob_score=True\n",
    ")\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print(bag_clf.oob_score_)\n",
    "print(confusion_matrix(y_test, bag_clf.predict(X_test)))\n",
    "print(accuracy_score(y_test, bag_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[881 115]\n",
      " [149 855]]\n",
      "0.868\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "print(confusion_matrix(y_test, rnd_clf.predict(X_test)))\n",
    "print(accuracy_score(y_test, rnd_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1084  158]\n",
      " [ 183 1075]]\n",
      "[[1074  168]\n",
      " [ 199 1059]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "gbrt = GradientBoostingClassifier(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [precision_score(y_test, pred) for pred in gbrt.staged_predict(X_test)]\n",
    "best_n_estimators = np.argmin(errors) + 1\n",
    "\n",
    "gbrt_best = GradientBoostingClassifier(max_depth=2, n_estimators=best_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)\n",
    "\n",
    "print(confusion_matrix(y_test, gbrt.predict(X_test)))\n",
    "print(confusion_matrix(y_test, gbrt_best.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1074  168]\n",
      " [ 199 1059]]\n",
      "[[1082  160]\n",
      " [ 207 1051]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "xgb = xgboost.XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "print(confusion_matrix(y_test, gbrt_best.predict(X_test)))\n",
    "print(confusion_matrix(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784) (50000,) (10000, 784) (10000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=(1/7))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=(1/6))\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rnd = RandomForestClassifier(max_leaf_nodes=12)\n",
    "ext = ExtraTreesClassifier(max_leaf_nodes=12)\n",
    "bag = BaggingClassifier(\n",
    "  LogisticRegression(multi_class='multinomial'),\n",
    "  n_estimators=10,\n",
    "  max_samples=100, bootstrap=True, n_jobs=-1, # Use all cores\n",
    "  oob_score=True\n",
    ")\n",
    "voting = VotingClassifier(\n",
    "  estimators=[\n",
    "    ('rnd', rnd), ('ext', ext), ('bag', bag),\n",
    "  ],\n",
    "  n_jobs=-1,\n",
    "  voting='soft',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 976    1    5    6    4    1    9    1    9    2]\n",
      " [   0 1150    2    8    0    2    2    1    5    1]\n",
      " [  17   72  729   12   21    0   29   20   38    0]\n",
      " [  13   31   18  865    2    9    6   25   39   15]\n",
      " [   4   24    8    1  849    1    5    1    5   74]\n",
      " [  39   64    2  139   26  519   29   11   17   42]\n",
      " [  24   38   15    1   15   12  926    1    4    0]\n",
      " [  11   43   11    4   22    0    0  955    4   26]\n",
      " [   7   99    5   68    9    9    5    7  673   39]\n",
      " [  13   19    4   22   54    0    2   32    5  810]]\n"
     ]
    }
   ],
   "source": [
    "voting.fit(X_train, y_train)\n",
    "print(confusion_matrix(y_val, voting.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 978    2    5    5    1    0    5    3   15    0]\n",
      " [   0 1146    5    7    1    1    3    2    4    2]\n",
      " [  25   56  737   27   16    2   28   28   12    7]\n",
      " [  35   32   29  816    5    8    4   24   27   43]\n",
      " [   4    9    6    4  756    0   27   17   15  134]\n",
      " [  92   41    4  277   34  277   30   23   25   85]\n",
      " [  42   31   24   17   32    7  869    4   10    0]\n",
      " [  10   30   23    1   17    0    0  949    7   39]\n",
      " [   4  106   23   80   10    2   14   10  616   56]\n",
      " [  15    7    6   22   51    0    7   90   12  751]]\n"
     ]
    }
   ],
   "source": [
    "rnd.fit(X_train, y_train)\n",
    "print(confusion_matrix(y_val, rnd.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 965    0    4   10    1    0   19    7    8    0]\n",
      " [   0 1151    3    5    0    2    1    2    6    1]\n",
      " [  37   91  695   24   26    0   22   35    7    1]\n",
      " [  28   41   19  845    3    8    3   27   23   26]\n",
      " [   7   16    7    4  792    1   27   41    9   68]\n",
      " [  72   38    8  310   47  252   24   41   26   70]\n",
      " [  64   41   18   28   22    3  846    9    5    0]\n",
      " [  10   53   21    3   12    0    0  944    3   30]\n",
      " [  13  133   26   96   12    2   15   14  571   39]\n",
      " [  11   22    6   33   93    3   14  104    3  672]]\n"
     ]
    }
   ],
   "source": [
    "ext.fit(X_train, y_train)\n",
    "print(confusion_matrix(y_val, ext.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlschader/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 980    1    6    3    4   10    4    3    3    0]\n",
      " [   0 1148    3    1    1    3    2    1   12    0]\n",
      " [   8   64  758   20   29    1   20   19   19    0]\n",
      " [  11   28   30  809    2   48    3   21   43   28]\n",
      " [   1   47    3    0  846    1    4    1    2   67]\n",
      " [  26   68    7   38   22  664   18    6   13   26]\n",
      " [  19   69   14    0   17   42  872    0    3    0]\n",
      " [  11   49    9    4   36    2    0  911    2   52]\n",
      " [  18  100   21   27   19   35    4   10  649   38]\n",
      " [  14   26    4   13   93    3    0   32    3  773]]\n"
     ]
    }
   ],
   "source": [
    "bag.fit(X_train, y_train)\n",
    "print(confusion_matrix(y_val, bag.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.8452\n",
      "RandomForestClassifier 0.7895\n",
      "ExtraTreesClassifier 0.7733\n",
      "BaggingClassifier 0.841\n"
     ]
    }
   ],
   "source": [
    "for clf in (voting, rnd, ext, bag):\n",
    "  print(clf.__class__.__name__, accuracy_score(y_val, clf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.8396\n",
      "RandomForestClassifier 0.7841\n",
      "ExtraTreesClassifier 0.7684\n",
      "BaggingClassifier 0.8334\n"
     ]
    }
   ],
   "source": [
    "for clf in (voting, rnd, ext, bag):\n",
    "  print(clf.__class__.__name__, accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class MNIST_Transformer(TransformerMixin):\n",
    "  def __init__(self, clfs=[]):\n",
    "    self.clfs = clfs\n",
    "  \n",
    "  def fit(self, X, y=None):\n",
    "    return self\n",
    "\n",
    "  def transform(self, X, y=None):\n",
    "    return np.concatenate([clf.predict(X).astype(np.int32).reshape(-1, 1) for clf in self.clfs], axis=1)\n",
    "\n",
    "transformer = MNIST_Transformer(clfs=[rnd, ext, bag, voting])\n",
    "\n",
    "X_meta = transformer.fit_transform(X_val)\n",
    "X_meta_test = transformer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 945    0   10    1    2   12   10    5    6    0]\n",
      " [   0 1102    5    5    0    2    2    6    7    2]\n",
      " [   8   24  848   21   23    2   27   30   23    4]\n",
      " [   8   23   32  774    3   44   12   12   45   15]\n",
      " [   1    7    7    1  852   10   12   11   12   61]\n",
      " [  21   34    6   58   29  694   12    8   28   31]\n",
      " [  19   20   26    4   11   18  870    3   11    2]\n",
      " [   7   19   12    6    9    4    2  902    2   31]\n",
      " [  11   60   30   50   12   22    9    8  799   30]\n",
      " [   7   11   10   12   58    6    0   60   16  816]]\n",
      "0.8602\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "  ('transformer', transformer),\n",
    "  ('meta_clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "clf.fit(X_val, y_val)\n",
    "print(confusion_matrix(y_test, clf.predict(X_test)))\n",
    "print(accuracy_score(y_test, clf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9120ca18d9a6352a9f63d878cd22df8740658f703b5d617e89c0216f7e3927ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
