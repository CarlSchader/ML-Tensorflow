{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 331) (45000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# (X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# # nopca\n",
    "# X_train_full = X_train_full.reshape(len(X_train_full), 28*28)\n",
    "# X_test = X_test.reshape(len(X_test), 28*28)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "# pca\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_full_pca = pca.fit_transform(X_train_full.reshape(len(X_train_full), 28*28))\n",
    "X_test = pca.transform(X_test.reshape(len(X_test), 28*28))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full_pca, y_train_full)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_nodes=10, lr=0.005, input_shape=(28, 28), output_nodes=10, output_activation='softmax', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'], l1=0.01, l2=0.01, dropout=0.2):\n",
    "  model = keras.models.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "  model.add(keras.layers.BatchNormalization())\n",
    "  for i in range(n_hidden):\n",
    "    model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(int(n_nodes / (i + 1)), activation='elu', kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1, l2)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "  model.add(keras.layers.Dropout(dropout))\n",
    "  model.add(keras.layers.Dense(output_nodes, activation=output_activation, kernel_regularizer=tf.keras.regularizers.l1_l2(l1, l2)))\n",
    "  # nestorov momentum\n",
    "  optimizer = keras.optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True)\n",
    "  # optimizer = keras.optimizers.RMSprop(learning_rate=lr, rho=0.9)\n",
    "  # optimizer = keras.optimizers.Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
    "  # optimizer = keras.optimizers.Nadam(learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_98 (Flatten)        (None, 331)               0         \n",
      "                                                                 \n",
      " batch_normalization_734 (Ba  (None, 331)              1324      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 331)               0         \n",
      "                                                                 \n",
      " dense_733 (Dense)           (None, 350)               116200    \n",
      "                                                                 \n",
      " batch_normalization_735 (Ba  (None, 350)              1400      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 350)               0         \n",
      "                                                                 \n",
      " dense_734 (Dense)           (None, 175)               61425     \n",
      "                                                                 \n",
      " batch_normalization_736 (Ba  (None, 175)              700       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 175)               0         \n",
      "                                                                 \n",
      " dense_735 (Dense)           (None, 116)               20416     \n",
      "                                                                 \n",
      " batch_normalization_737 (Ba  (None, 116)              464       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 116)               0         \n",
      "                                                                 \n",
      " dense_736 (Dense)           (None, 87)                10179     \n",
      "                                                                 \n",
      " batch_normalization_738 (Ba  (None, 87)               348       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 87)                0         \n",
      "                                                                 \n",
      " dense_737 (Dense)           (None, 70)                6160      \n",
      "                                                                 \n",
      " batch_normalization_739 (Ba  (None, 70)               280       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 70)                0         \n",
      "                                                                 \n",
      " dense_738 (Dense)           (None, 58)                4118      \n",
      "                                                                 \n",
      " batch_normalization_740 (Ba  (None, 58)               232       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 58)                0         \n",
      "                                                                 \n",
      " dense_739 (Dense)           (None, 50)                2950      \n",
      "                                                                 \n",
      " batch_normalization_741 (Ba  (None, 50)               200       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_740 (Dense)           (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,906\n",
      "Trainable params: 224,432\n",
      "Non-trainable params: 2,474\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/256\n",
      "1407/1407 [==============================] - 6s 3ms/step - loss: 2.4593 - sparse_categorical_accuracy: 0.6813 - val_loss: 1.4225 - val_sparse_categorical_accuracy: 0.9079 - lr: 0.0350\n",
      "Epoch 2/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5970 - sparse_categorical_accuracy: 0.7962 - val_loss: 1.0155 - val_sparse_categorical_accuracy: 0.9329 - lr: 0.0350\n",
      "Epoch 3/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3265 - sparse_categorical_accuracy: 0.8200 - val_loss: 0.8864 - val_sparse_categorical_accuracy: 0.9395 - lr: 0.0350\n",
      "Epoch 4/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.2341 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.8628 - val_sparse_categorical_accuracy: 0.9426 - lr: 0.0350\n",
      "Epoch 5/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1936 - sparse_categorical_accuracy: 0.8416 - val_loss: 0.8612 - val_sparse_categorical_accuracy: 0.9358 - lr: 0.0350\n",
      "Epoch 6/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1826 - sparse_categorical_accuracy: 0.8440 - val_loss: 0.8359 - val_sparse_categorical_accuracy: 0.9493 - lr: 0.0350\n",
      "Epoch 7/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1582 - sparse_categorical_accuracy: 0.8509 - val_loss: 0.8351 - val_sparse_categorical_accuracy: 0.9471 - lr: 0.0350\n",
      "Epoch 8/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1539 - sparse_categorical_accuracy: 0.8523 - val_loss: 0.8119 - val_sparse_categorical_accuracy: 0.9526 - lr: 0.0350\n",
      "Epoch 9/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1426 - sparse_categorical_accuracy: 0.8564 - val_loss: 0.8124 - val_sparse_categorical_accuracy: 0.9508 - lr: 0.0350\n",
      "Epoch 10/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1382 - sparse_categorical_accuracy: 0.8571 - val_loss: 0.7933 - val_sparse_categorical_accuracy: 0.9585 - lr: 0.0350\n",
      "Epoch 11/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1307 - sparse_categorical_accuracy: 0.8578 - val_loss: 0.8057 - val_sparse_categorical_accuracy: 0.9522 - lr: 0.0350\n",
      "Epoch 12/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1325 - sparse_categorical_accuracy: 0.8580 - val_loss: 0.8096 - val_sparse_categorical_accuracy: 0.9541 - lr: 0.0350\n",
      "Epoch 13/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1227 - sparse_categorical_accuracy: 0.8604 - val_loss: 0.7813 - val_sparse_categorical_accuracy: 0.9567 - lr: 0.0350\n",
      "Epoch 14/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1106 - sparse_categorical_accuracy: 0.8629 - val_loss: 0.7855 - val_sparse_categorical_accuracy: 0.9599 - lr: 0.0350\n",
      "Epoch 15/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1056 - sparse_categorical_accuracy: 0.8650 - val_loss: 0.7798 - val_sparse_categorical_accuracy: 0.9605 - lr: 0.0350\n",
      "Epoch 16/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1068 - sparse_categorical_accuracy: 0.8640 - val_loss: 0.7807 - val_sparse_categorical_accuracy: 0.9565 - lr: 0.0350\n",
      "Epoch 17/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1077 - sparse_categorical_accuracy: 0.8631 - val_loss: 0.8005 - val_sparse_categorical_accuracy: 0.9503 - lr: 0.0350\n",
      "Epoch 18/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.1086 - sparse_categorical_accuracy: 0.8642 - val_loss: 0.7848 - val_sparse_categorical_accuracy: 0.9575 - lr: 0.0350\n",
      "Epoch 19/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0897 - sparse_categorical_accuracy: 0.8664 - val_loss: 0.7745 - val_sparse_categorical_accuracy: 0.9566 - lr: 0.0350\n",
      "Epoch 20/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0817 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.7915 - val_sparse_categorical_accuracy: 0.9515 - lr: 0.0350\n",
      "Epoch 21/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0933 - sparse_categorical_accuracy: 0.8650 - val_loss: 0.7961 - val_sparse_categorical_accuracy: 0.9505 - lr: 0.0350\n",
      "Epoch 22/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0884 - sparse_categorical_accuracy: 0.8649 - val_loss: 0.7790 - val_sparse_categorical_accuracy: 0.9564 - lr: 0.0350\n",
      "Epoch 23/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0791 - sparse_categorical_accuracy: 0.8668 - val_loss: 0.7687 - val_sparse_categorical_accuracy: 0.9598 - lr: 0.0350\n",
      "Epoch 24/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0771 - sparse_categorical_accuracy: 0.8675 - val_loss: 0.7732 - val_sparse_categorical_accuracy: 0.9565 - lr: 0.0350\n",
      "Epoch 25/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0769 - sparse_categorical_accuracy: 0.8674 - val_loss: 0.7726 - val_sparse_categorical_accuracy: 0.9579 - lr: 0.0350\n",
      "Epoch 26/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0784 - sparse_categorical_accuracy: 0.8692 - val_loss: 0.7815 - val_sparse_categorical_accuracy: 0.9549 - lr: 0.0350\n",
      "Epoch 27/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0817 - sparse_categorical_accuracy: 0.8677 - val_loss: 0.7572 - val_sparse_categorical_accuracy: 0.9609 - lr: 0.0350\n",
      "Epoch 28/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0696 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.7516 - val_sparse_categorical_accuracy: 0.9621 - lr: 0.0350\n",
      "Epoch 29/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0835 - sparse_categorical_accuracy: 0.8674 - val_loss: 0.7507 - val_sparse_categorical_accuracy: 0.9625 - lr: 0.0350\n",
      "Epoch 30/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0736 - sparse_categorical_accuracy: 0.8696 - val_loss: 0.7560 - val_sparse_categorical_accuracy: 0.9598 - lr: 0.0350\n",
      "Epoch 31/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0660 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.7578 - val_sparse_categorical_accuracy: 0.9602 - lr: 0.0350\n",
      "Epoch 32/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0799 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.7542 - val_sparse_categorical_accuracy: 0.9643 - lr: 0.0350\n",
      "Epoch 33/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0732 - sparse_categorical_accuracy: 0.8688 - val_loss: 0.7507 - val_sparse_categorical_accuracy: 0.9631 - lr: 0.0350\n",
      "Epoch 34/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0705 - sparse_categorical_accuracy: 0.8685 - val_loss: 0.7723 - val_sparse_categorical_accuracy: 0.9542 - lr: 0.0350\n",
      "Epoch 35/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.0062 - sparse_categorical_accuracy: 0.8775 - val_loss: 0.7010 - val_sparse_categorical_accuracy: 0.9603 - lr: 0.0280\n",
      "Epoch 36/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9870 - sparse_categorical_accuracy: 0.8758 - val_loss: 0.6973 - val_sparse_categorical_accuracy: 0.9627 - lr: 0.0280\n",
      "Epoch 37/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9835 - sparse_categorical_accuracy: 0.8765 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.9605 - lr: 0.0280\n",
      "Epoch 38/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9930 - sparse_categorical_accuracy: 0.8742 - val_loss: 0.7070 - val_sparse_categorical_accuracy: 0.9631 - lr: 0.0280\n",
      "Epoch 39/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9849 - sparse_categorical_accuracy: 0.8769 - val_loss: 0.6821 - val_sparse_categorical_accuracy: 0.9637 - lr: 0.0280\n",
      "Epoch 40/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9792 - sparse_categorical_accuracy: 0.8753 - val_loss: 0.6765 - val_sparse_categorical_accuracy: 0.9676 - lr: 0.0280\n",
      "Epoch 41/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9784 - sparse_categorical_accuracy: 0.8773 - val_loss: 0.6854 - val_sparse_categorical_accuracy: 0.9654 - lr: 0.0280\n",
      "Epoch 42/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9860 - sparse_categorical_accuracy: 0.8761 - val_loss: 0.6971 - val_sparse_categorical_accuracy: 0.9643 - lr: 0.0280\n",
      "Epoch 43/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9834 - sparse_categorical_accuracy: 0.8787 - val_loss: 0.6799 - val_sparse_categorical_accuracy: 0.9642 - lr: 0.0280\n",
      "Epoch 44/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9805 - sparse_categorical_accuracy: 0.8767 - val_loss: 0.7143 - val_sparse_categorical_accuracy: 0.9582 - lr: 0.0280\n",
      "Epoch 45/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9824 - sparse_categorical_accuracy: 0.8770 - val_loss: 0.7309 - val_sparse_categorical_accuracy: 0.9527 - lr: 0.0280\n",
      "Epoch 46/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9257 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.6585 - val_sparse_categorical_accuracy: 0.9606 - lr: 0.0224\n",
      "Epoch 47/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9181 - sparse_categorical_accuracy: 0.8841 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.9669 - lr: 0.0224\n",
      "Epoch 48/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9107 - sparse_categorical_accuracy: 0.8868 - val_loss: 0.6313 - val_sparse_categorical_accuracy: 0.9660 - lr: 0.0224\n",
      "Epoch 49/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9102 - sparse_categorical_accuracy: 0.8832 - val_loss: 0.6512 - val_sparse_categorical_accuracy: 0.9621 - lr: 0.0224\n",
      "Epoch 50/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9101 - sparse_categorical_accuracy: 0.8852 - val_loss: 0.6323 - val_sparse_categorical_accuracy: 0.9670 - lr: 0.0224\n",
      "Epoch 51/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9086 - sparse_categorical_accuracy: 0.8827 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.9639 - lr: 0.0224\n",
      "Epoch 52/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9154 - sparse_categorical_accuracy: 0.8846 - val_loss: 0.6299 - val_sparse_categorical_accuracy: 0.9660 - lr: 0.0224\n",
      "Epoch 53/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9115 - sparse_categorical_accuracy: 0.8843 - val_loss: 0.6267 - val_sparse_categorical_accuracy: 0.9679 - lr: 0.0224\n",
      "Epoch 54/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9084 - sparse_categorical_accuracy: 0.8837 - val_loss: 0.6311 - val_sparse_categorical_accuracy: 0.9654 - lr: 0.0224\n",
      "Epoch 55/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9130 - sparse_categorical_accuracy: 0.8836 - val_loss: 0.6384 - val_sparse_categorical_accuracy: 0.9646 - lr: 0.0224\n",
      "Epoch 56/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9079 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.6262 - val_sparse_categorical_accuracy: 0.9667 - lr: 0.0224\n",
      "Epoch 57/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9095 - sparse_categorical_accuracy: 0.8849 - val_loss: 0.6337 - val_sparse_categorical_accuracy: 0.9655 - lr: 0.0224\n",
      "Epoch 58/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9163 - sparse_categorical_accuracy: 0.8850 - val_loss: 0.6376 - val_sparse_categorical_accuracy: 0.9663 - lr: 0.0224\n",
      "Epoch 59/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9088 - sparse_categorical_accuracy: 0.8860 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.9637 - lr: 0.0224\n",
      "Epoch 60/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9228 - sparse_categorical_accuracy: 0.8823 - val_loss: 0.6565 - val_sparse_categorical_accuracy: 0.9617 - lr: 0.0224\n",
      "Epoch 61/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.9079 - sparse_categorical_accuracy: 0.8856 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.9657 - lr: 0.0224\n",
      "Epoch 62/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8587 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.5922 - val_sparse_categorical_accuracy: 0.9689 - lr: 0.0179\n",
      "Epoch 63/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8469 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.5754 - val_sparse_categorical_accuracy: 0.9704 - lr: 0.0179\n",
      "Epoch 64/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8534 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.5849 - val_sparse_categorical_accuracy: 0.9687 - lr: 0.0179\n",
      "Epoch 65/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8538 - sparse_categorical_accuracy: 0.8890 - val_loss: 0.5953 - val_sparse_categorical_accuracy: 0.9650 - lr: 0.0179\n",
      "Epoch 66/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8435 - sparse_categorical_accuracy: 0.8907 - val_loss: 0.5875 - val_sparse_categorical_accuracy: 0.9675 - lr: 0.0179\n",
      "Epoch 67/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8368 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.5903 - val_sparse_categorical_accuracy: 0.9657 - lr: 0.0179\n",
      "Epoch 68/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8501 - sparse_categorical_accuracy: 0.8901 - val_loss: 0.5852 - val_sparse_categorical_accuracy: 0.9701 - lr: 0.0179\n",
      "Epoch 69/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.8016 - sparse_categorical_accuracy: 0.8991 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.9703 - lr: 0.0143\n",
      "Epoch 70/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7852 - sparse_categorical_accuracy: 0.8988 - val_loss: 0.5456 - val_sparse_categorical_accuracy: 0.9683 - lr: 0.0143\n",
      "Epoch 71/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7864 - sparse_categorical_accuracy: 0.8959 - val_loss: 0.5371 - val_sparse_categorical_accuracy: 0.9712 - lr: 0.0143\n",
      "Epoch 72/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7827 - sparse_categorical_accuracy: 0.8972 - val_loss: 0.5415 - val_sparse_categorical_accuracy: 0.9697 - lr: 0.0143\n",
      "Epoch 73/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7915 - sparse_categorical_accuracy: 0.8954 - val_loss: 0.5401 - val_sparse_categorical_accuracy: 0.9692 - lr: 0.0143\n",
      "Epoch 74/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7948 - sparse_categorical_accuracy: 0.8963 - val_loss: 0.5424 - val_sparse_categorical_accuracy: 0.9705 - lr: 0.0143\n",
      "Epoch 75/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7925 - sparse_categorical_accuracy: 0.8968 - val_loss: 0.5427 - val_sparse_categorical_accuracy: 0.9692 - lr: 0.0143\n",
      "Epoch 76/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7806 - sparse_categorical_accuracy: 0.8981 - val_loss: 0.5455 - val_sparse_categorical_accuracy: 0.9690 - lr: 0.0143\n",
      "Epoch 77/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7604 - sparse_categorical_accuracy: 0.9020 - val_loss: 0.5084 - val_sparse_categorical_accuracy: 0.9729 - lr: 0.0115\n",
      "Epoch 78/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7367 - sparse_categorical_accuracy: 0.9050 - val_loss: 0.5083 - val_sparse_categorical_accuracy: 0.9712 - lr: 0.0115\n",
      "Epoch 79/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7386 - sparse_categorical_accuracy: 0.9023 - val_loss: 0.4954 - val_sparse_categorical_accuracy: 0.9731 - lr: 0.0115\n",
      "Epoch 80/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7313 - sparse_categorical_accuracy: 0.9031 - val_loss: 0.4992 - val_sparse_categorical_accuracy: 0.9732 - lr: 0.0115\n",
      "Epoch 81/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7442 - sparse_categorical_accuracy: 0.9006 - val_loss: 0.5084 - val_sparse_categorical_accuracy: 0.9703 - lr: 0.0115\n",
      "Epoch 82/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7348 - sparse_categorical_accuracy: 0.9024 - val_loss: 0.4970 - val_sparse_categorical_accuracy: 0.9719 - lr: 0.0115\n",
      "Epoch 83/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7370 - sparse_categorical_accuracy: 0.9006 - val_loss: 0.5016 - val_sparse_categorical_accuracy: 0.9715 - lr: 0.0115\n",
      "Epoch 84/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7374 - sparse_categorical_accuracy: 0.9035 - val_loss: 0.5101 - val_sparse_categorical_accuracy: 0.9687 - lr: 0.0115\n",
      "Epoch 85/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7097 - sparse_categorical_accuracy: 0.9061 - val_loss: 0.4728 - val_sparse_categorical_accuracy: 0.9757 - lr: 0.0092\n",
      "Epoch 86/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6972 - sparse_categorical_accuracy: 0.9068 - val_loss: 0.4721 - val_sparse_categorical_accuracy: 0.9738 - lr: 0.0092\n",
      "Epoch 87/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6943 - sparse_categorical_accuracy: 0.9067 - val_loss: 0.4711 - val_sparse_categorical_accuracy: 0.9738 - lr: 0.0092\n",
      "Epoch 88/256\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.6909 - sparse_categorical_accuracy: 0.9067 - val_loss: 0.4768 - val_sparse_categorical_accuracy: 0.9717 - lr: 0.0092\n",
      "Epoch 89/256\n",
      "1016/1407 [====================>.........] - ETA: 1s - loss: 0.6885 - sparse_categorical_accuracy: 0.9085"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m build_model(\u001b[39m7\u001b[39m, \u001b[39m350\u001b[39m, \u001b[39m0.035\u001b[39m, X_test\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:], \u001b[39m10\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39msparse_categorical_crossentropy, metrics\u001b[39m=\u001b[39m[keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39msparse_categorical_accuracy], l1\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m, l2\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m, dropout\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), callbacks\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   \u001b[39m# keras.callbacks.TensorBoard(get_run_log_dir()),\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mModelCheckpoint(save_dir, save_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(patience\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m, restore_best_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m   keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mReduceLROnPlateau(factor\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m,patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m ])\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_dir = os.path.join(os.curdir, 'model.h5')\n",
    "\n",
    "model = build_model(7, 350, 0.035, X_test.shape[1:], 10, 'softmax', loss=keras.losses.sparse_categorical_crossentropy, metrics=[keras.metrics.sparse_categorical_accuracy], l1=0, l2=0.001, dropout=0.2)\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=256, validation_data=(X_val, y_val), callbacks=[\n",
    "  # keras.callbacks.TensorBoard(get_run_log_dir()),\n",
    "  keras.callbacks.ModelCheckpoint(save_dir, save_best_only=True),\n",
    "  keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True),\n",
    "  keras.callbacks.ReduceLROnPlateau(factor=0.8,patience=5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "[[ 972    1    1    0    0    0    1    1    3    1]\n",
      " [   0 1132    2    0    0    0    0    0    1    0]\n",
      " [   7    0 1010    2    0    0    0    6    7    0]\n",
      " [   0    0   14  962    0   11    0    8   13    2]\n",
      " [   0    0    4    0  961    0    4    0    3   10]\n",
      " [   3    1    0    8    0  864    5    2    7    2]\n",
      " [  14    3    0    1    4    2  930    0    4    0]\n",
      " [   2    6   15    0    1    0    0  991    2   11]\n",
      " [   4    1    2    2    1    1    3    4  949    7]\n",
      " [   7    2    0    7   11    1    0    7    5  969]]\n",
      "0.974\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "loaded = keras.models.load_model(save_dir)\n",
    "pred = loaded.predict(X_test)\n",
    "print(confusion_matrix(y_test, np.argmax(pred, axis=1)))\n",
    "print(accuracy_score(y_test, np.argmax(pred, axis=1)))\n",
    "\n",
    "# best so far\n",
    "# pca = PCA(n_components=0.98)\n",
    "# build_model(6, 300, 0.035, X_test_pca.shape[1:], 10, 'softmax', loss=keras.losses.sparse_categorical_crossentropy, metrics=[keras.metrics.sparse_categorical_accuracy], l1=0.01, l2=0.0005)\n",
    "# optimizer = keras.optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True)\n",
    "# keras.callbacks.ReduceLROnPlateau(factor=0.8,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 963    0    3    0    1    5    5    1    2    0]\n",
      " [   0 1115    6    4    0    0    6    0    4    0]\n",
      " [   8    0  952   13   10    1    3    8   34    3]\n",
      " [   3    0   11  943    0   16    2   10   19    6]\n",
      " [   0    1   10    0  929    2    8    2    7   23]\n",
      " [   5    1    6   37   10  806   10    4    8    5]\n",
      " [  10    3    5    0    4    4  929    0    3    0]\n",
      " [   2   11   20    4    7    0    0  957    2   25]\n",
      " [   5    0   13   35   11   24    6    3  865   12]\n",
      " [  10    7    5   16   33    2    1   18    7  910]]\n",
      "0.9369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 444)\n",
      "deer\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class_names = [\n",
    "  'airplane',\n",
    "  'automobile',\n",
    "  'bird',\n",
    "  'cat',\n",
    "  'deer',\n",
    "  'dog',\n",
    "  'frog',\n",
    "  'horse',\n",
    "  'ship',\n",
    "  'truck'\n",
    "]\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "print(X_train_full.shape)\n",
    "\n",
    "pca = PCA(n_components=0.98)\n",
    "X_train_full = pca.fit_transform(X_train_full.reshape(len(X_train_full), 32*32*3))\n",
    "X_test = pca.transform(X_test.reshape(len(X_test), 32*32*3))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)\n",
    "print(X_train_full.shape)\n",
    "# plt.imshow(X_test[100])\n",
    "print(class_names[y_test[100][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_42 (Flatten)        (None, 444)               0         \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 444)               0         \n",
      "                                                                 \n",
      " batch_normalization_172 (Ba  (None, 444)              1776      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 444)               0         \n",
      "                                                                 \n",
      " dense_529 (Dense)           (None, 800)               356000    \n",
      "                                                                 \n",
      " batch_normalization_173 (Ba  (None, 800)              3200      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 800)               0         \n",
      "                                                                 \n",
      " dense_530 (Dense)           (None, 800)               640800    \n",
      "                                                                 \n",
      " batch_normalization_174 (Ba  (None, 800)              3200      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 800)               0         \n",
      "                                                                 \n",
      " dense_531 (Dense)           (None, 800)               640800    \n",
      "                                                                 \n",
      " batch_normalization_175 (Ba  (None, 800)              3200      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 800)               0         \n",
      "                                                                 \n",
      " dense_532 (Dense)           (None, 800)               640800    \n",
      "                                                                 \n",
      " batch_normalization_176 (Ba  (None, 800)              3200      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 800)               0         \n",
      "                                                                 \n",
      " dense_533 (Dense)           (None, 800)               640800    \n",
      "                                                                 \n",
      " batch_normalization_177 (Ba  (None, 800)              3200      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_534 (Dense)           (None, 10)                8010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,944,986\n",
      "Trainable params: 2,936,098\n",
      "Non-trainable params: 8,888\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/256\n",
      "1172/1172 [==============================] - 15s 11ms/step - loss: 2.4806 - sparse_categorical_accuracy: 0.2300 - val_loss: 1.8008 - val_sparse_categorical_accuracy: 0.3504 - lr: 0.0500\n",
      "Epoch 2/256\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 1.9041 - sparse_categorical_accuracy: 0.3168 - val_loss: 1.7650 - val_sparse_categorical_accuracy: 0.3673 - lr: 0.0500\n",
      "Epoch 3/256\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 1.8366 - sparse_categorical_accuracy: 0.3464 - val_loss: 1.6588 - val_sparse_categorical_accuracy: 0.4063 - lr: 0.0500\n",
      "Epoch 4/256\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 1.7898 - sparse_categorical_accuracy: 0.3600 - val_loss: 1.6350 - val_sparse_categorical_accuracy: 0.4278 - lr: 0.0500\n",
      "Epoch 5/256\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 1.7457 - sparse_categorical_accuracy: 0.3807 - val_loss: 1.5782 - val_sparse_categorical_accuracy: 0.4417 - lr: 0.0500\n",
      "Epoch 6/256\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 1.7123 - sparse_categorical_accuracy: 0.3922 - val_loss: 1.5659 - val_sparse_categorical_accuracy: 0.4522 - lr: 0.0500\n",
      "Epoch 7/256\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 1.6662 - sparse_categorical_accuracy: 0.4103 - val_loss: 1.4856 - val_sparse_categorical_accuracy: 0.4607 - lr: 0.0500\n",
      "Epoch 8/256\n",
      "1172/1172 [==============================] - 11s 10ms/step - loss: 1.6348 - sparse_categorical_accuracy: 0.4200 - val_loss: 1.5256 - val_sparse_categorical_accuracy: 0.4489 - lr: 0.0500\n",
      "Epoch 9/256\n",
      "1172/1172 [==============================] - 12s 10ms/step - loss: 1.5996 - sparse_categorical_accuracy: 0.4320 - val_loss: 1.4529 - val_sparse_categorical_accuracy: 0.4791 - lr: 0.0500\n",
      "Epoch 10/256\n",
      " 515/1172 [============>.................] - ETA: 6s - loss: 1.5762 - sparse_categorical_accuracy: 0.4374"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m   optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate\u001b[39m=\u001b[39mlr, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m, nesterov\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m   \u001b[39m# optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m   loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39msparse_categorical_crossentropy,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m   metrics\u001b[39m=\u001b[39m(keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39msparse_categorical_accuracy),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msummary())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), callbacks\u001b[39m=\u001b[39;49m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m   keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mTensorBoard(get_run_log_dir()),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m   keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mModelCheckpoint(save_dir, save_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m   keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mEarlyStopping(patience\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, restore_best_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m   keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mReduceLROnPlateau(factor\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/carlschader/programming/ml-tensorflow/ch11/ch11.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m ))\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/programming/ml-tensorflow/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "log_dir = os.path.join(os.curdir, 'logs')\n",
    "save_dir = os.path.join(os.curdir, 'cifar.h5')\n",
    "hidden = 5\n",
    "neurons = 800\n",
    "lr = 0.05\n",
    "l2 = 0\n",
    "dropout = True\n",
    "dropout_val = 0.2\n",
    "\n",
    "def get_run_log_dir():\n",
    "  run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "  return os.path.join(log_dir, run_id)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=X_test.shape[1:]))\n",
    "if dropout:\n",
    "  model.add(keras.layers.Dropout(dropout_val))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for i in range(hidden):\n",
    "  if dropout:\n",
    "    model.add(keras.layers.Dropout(dropout_val))\n",
    "  model.add(keras.layers.Dense(neurons, kernel_initializer='he_normal', activation='elu', kernel_regularizer=keras.regularizers.l2(l2)))\n",
    "  model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(len(class_names), activation='softmax', kernel_regularizer=keras.regularizers.l2(l2)))\n",
    "\n",
    "model.compile(\n",
    "  optimizer=keras.optimizers.SGD(learning_rate=lr, momentum=0.9, nesterov=True),\n",
    "  # optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "  loss=keras.losses.sparse_categorical_crossentropy,\n",
    "  metrics=(keras.metrics.sparse_categorical_accuracy),\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, epochs=256, validation_data=(X_val, y_val), callbacks=(\n",
    "  keras.callbacks.TensorBoard(get_run_log_dir()),\n",
    "  keras.callbacks.ModelCheckpoint(save_dir, save_best_only=True),\n",
    "  keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True),\n",
    "  keras.callbacks.ReduceLROnPlateau(factor=0.8, patience=5),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "[[610   7  72  19  33  15  23   9 169  43]\n",
      " [ 82 491  25  27  17  23  37  20 143 135]\n",
      " [ 82   1 460  36 178  90  92  28  26   7]\n",
      " [ 30   5 120 202 128 284 155  30  27  19]\n",
      " [ 50   1 131  29 579  50  82  49  23   6]\n",
      " [ 21   3 117 105 124 519  55  42   9   5]\n",
      " [  6   5  65  19 144  48 692   7   8   6]\n",
      " [ 23   4  51  45 146 104  37 552  16  22]\n",
      " [ 90  15  24  11   9  19  22   5 773  32]\n",
      " [ 48  89  25  36  28  37  39  42 132 524]]\n",
      "0.5402\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "loaded = keras.models.load_model(save_dir)\n",
    "pred = loaded.predict(X_test)\n",
    "print(confusion_matrix(y_test, np.argmax(pred, axis=1)))\n",
    "print(accuracy_score(y_test, np.argmax(pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/q7k30xcj51x3tc06z506z3n00000gn/T/ipykernel_70935/1308907044.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[555  60  49  28  19  26  30  24 148  61]\n",
      " [ 40 579  23  32  12  25  23  28  67 171]\n",
      " [107  36 310  79 150  69 129  59  38  23]\n",
      " [ 55  49  98 271  51 180 123  63  29  81]\n",
      " [ 57  27 136  64 375  59 150  81  28  23]\n",
      " [ 35  43  86 164  60 373  94  75  38  32]\n",
      " [ 12  33  92  59 109  60 555  26  18  36]\n",
      " [ 41  47  49  62  75  98  70 432  34  92]\n",
      " [114  92  17  22  17  41  18  17 594  68]\n",
      " [ 48 190  17  43   9  34  34  37  84 504]]\n",
      "0.4548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9120ca18d9a6352a9f63d878cd22df8740658f703b5d617e89c0216f7e3927ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
